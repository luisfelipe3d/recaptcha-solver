{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0edcee-e391-45df-b5be-3b399090cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824d54ce-ea7c-4b16-b76f-d9af41676cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b789ce0d-38dd-4bd0-be5b-95ce21b115e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4521, 0.4465, 0.4503])\n",
      "Std: tensor([0.2017, 0.2024, 0.2017])\n"
     ]
    }
   ],
   "source": [
    "# Caminho para o seu dataset\n",
    "data_dir = './editedDataset'\n",
    "\n",
    "# Transformação para converter as imagens em tensores\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensiona as imagens (ajuste conforme necessário)\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Carregar o dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# DataLoader para iterar pelo dataset\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    "\n",
    "def calculate_mean_std(dataloader):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in dataloader:\n",
    "        # Redimensiona o batch: (batch_size, 3, height, width) para (3, batch_size*height*width)\n",
    "        images = images.view(3, -1)\n",
    "        \n",
    "        # Calcula a média e soma\n",
    "        mean += images.mean(1)\n",
    "        \n",
    "        # Calcula o desvio padrão e soma\n",
    "        std += images.std(1)\n",
    "        \n",
    "        total_images += 1\n",
    "\n",
    "    # Média total\n",
    "    mean /= total_images\n",
    "    \n",
    "    # Desvio padrão total\n",
    "    std /= total_images\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Calcula a média e o desvio padrão\n",
    "mean, std = calculate_mean_std(dataloader)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aba9590-81c5-4117-9cb2-4aa75f1e6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_dir, batch_size, random_seed=42, train_size=0.8, valid_size=0.1, shuffle=True):\n",
    "    # Define as transformações\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4521, 0.4465, 0.4503],  # Ajuste esses valores para o seu dataset\n",
    "        std=[0.2017, 0.2024, 0.2017],\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Carregar o dataset\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=data_dir,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    num_images = len(dataset)\n",
    "    print(f\"Total de imagens no dataset: {num_images}\")\n",
    "\n",
    "    num_train = len(dataset)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    # Divisão dos índices\n",
    "    train_split = int(np.floor(train_size * num_train))\n",
    "    valid_split = int(np.floor((train_size + valid_size) * num_train))\n",
    "\n",
    "    train_idx, valid_idx, test_idx = indices[:train_split], indices[train_split:valid_split], indices[valid_split:]\n",
    "\n",
    "    # Criar samplers\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # Criar data loaders\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    print(f\"Imagens de treinamento: {len(train_idx)}\")\n",
    "    print(f\"Imagens de validação: {len(valid_idx)}\")\n",
    "    print(f\"Imagens de teste: {len(test_idx)}\")\n",
    "\n",
    "    return (train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "774e56be-779a-4ae0-b01b-fef303153406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens no dataset: 4194\n",
      "Imagens de treinamento: 3355\n",
      "Imagens de validação: 419\n",
      "Imagens de teste: 420\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_size= 0.8\n",
    "valid_size = 0.1\n",
    "\n",
    "train_loader, valid_loader, test_loader = data_loader(data_dir=data_dir, batch_size=batch_size, \n",
    "                                                      train_size=train_size, valid_size=valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4fc674-5764-4797-ab61-9efb2c215f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, mid_channels=None, kernel_size=3, padding=1):\n",
    "        super(SCConv, self).__init__()\n",
    "        #print(in_channels,mid_channels)\n",
    "\n",
    "        self.k2 = nn.Sequential(\n",
    "                    nn.AvgPool2d(kernel_size=4, stride=4),\n",
    "                    nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, dilation=1, stride=1, bias=False, groups=1),\n",
    "                    nn.BatchNorm2d(in_channels),\n",
    "                    )\n",
    "        self.k3 = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, dilation=1, stride=1, bias=False, groups=1),\n",
    "                    nn.BatchNorm2d(in_channels),\n",
    "                    )\n",
    "        self.k4 = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, dilation=1, stride=1, bias=False, groups=1),\n",
    "                    nn.BatchNorm2d(mid_channels),\n",
    "                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = torch.sigmoid(torch.add(identity, F.interpolate(self.k2(x), identity.size()[2:]))) # sigmoid(identity + k2)\n",
    "        out = torch.mul(self.k3(x), out) # k3 * sigmoid(identity + k2)\n",
    "        out = self.k4(out) # k4\n",
    "\n",
    "        return out\n",
    "\n",
    "class SCVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(SCVGG16, self).__init__()\n",
    "        self.features = self._make_layers()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layers(self):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        \n",
    "        # Configuração da arquitetura VGG16\n",
    "        cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [SCConv(in_channels, v),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "                \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27634170-126a-49e2-904e-b1b2e86179f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001 # for Adam 0.0001 or 0.0004\n",
    "\n",
    "model = SCVGG16(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "classes = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Traffic Light']\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732eb179-7b02-4d5f-a059-583b7ad21e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [420/420], Loss: 1.801087\n",
      "Accuracy of the network on the validation images: 27.446301 %\n",
      "Accuracy of the network on the test images: 27.142857 %\n",
      "Precision: 0.216494, Recall: 0.271429, F1-Score: 0.220083\n",
      "Epoch [2/3], Step [420/420], Loss: 1.272842\n",
      "Accuracy of the network on the validation images: 39.856802 %\n",
      "Accuracy of the network on the test images: 41.666667 %\n",
      "Precision: 0.379968, Recall: 0.416667, F1-Score: 0.390391\n",
      "Epoch [3/3], Step [420/420], Loss: 1.387941\n",
      "Accuracy of the network on the validation images: 42.243437 %\n",
      "Accuracy of the network on the test images: 40.476190 %\n",
      "Precision: 0.379948, Recall: 0.404762, F1-Score: 0.357260\n",
      "Total training time: 217.736431 seconds.\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.6f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = f'checkpoint/checkpoint_{type(model).__name__}_num_epochs-{num_epochs}_epoch_{epoch+1}.pt'\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "        print('Accuracy of the network on the validation images: {:.6f} %'.format(accuracy))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), f'best/best_{type(model).__name__}_epoch_{num_epochs}.pt')\n",
    "\n",
    "    # Testing loop\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        print('Accuracy of the network on the test images: {:.6f} %'.format(accuracy))\n",
    "\n",
    "    # Calcula as métricas com tratamento de divisão por zero\n",
    "    precision = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    print(f'Precision: {precision:.6f}, Recall: {recall:.6f}, F1-Score: {f1:.6f}')\n",
    "\n",
    "# Synchronize after training completion if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()\n",
    "total_training_time = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {total_training_time:.6f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7eb1175-1c3b-4259-bd52-6ba0aa9f7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 and Self Calibrated Convolution Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         AvgPool2d-1            [-1, 3, 56, 56]               0\n",
      "            Conv2d-2            [-1, 3, 56, 56]              81\n",
      "       BatchNorm2d-3            [-1, 3, 56, 56]               6\n",
      "            Conv2d-4          [-1, 3, 224, 224]              81\n",
      "       BatchNorm2d-5          [-1, 3, 224, 224]               6\n",
      "            Conv2d-6         [-1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-7         [-1, 64, 224, 224]             128\n",
      "            SCConv-8         [-1, 64, 224, 224]               0\n",
      "              ReLU-9         [-1, 64, 224, 224]               0\n",
      "        AvgPool2d-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "           Conv2d-13         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-14         [-1, 64, 224, 224]             128\n",
      "           Conv2d-15         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 224, 224]             128\n",
      "           SCConv-17         [-1, 64, 224, 224]               0\n",
      "             ReLU-18         [-1, 64, 224, 224]               0\n",
      "        MaxPool2d-19         [-1, 64, 112, 112]               0\n",
      "        AvgPool2d-20           [-1, 64, 28, 28]               0\n",
      "           Conv2d-21           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 28, 28]             128\n",
      "           Conv2d-23         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-24         [-1, 64, 112, 112]             128\n",
      "           Conv2d-25        [-1, 128, 112, 112]          73,728\n",
      "      BatchNorm2d-26        [-1, 128, 112, 112]             256\n",
      "           SCConv-27        [-1, 128, 112, 112]               0\n",
      "             ReLU-28        [-1, 128, 112, 112]               0\n",
      "        AvgPool2d-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "           Conv2d-32        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-33        [-1, 128, 112, 112]             256\n",
      "           Conv2d-34        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-35        [-1, 128, 112, 112]             256\n",
      "           SCConv-36        [-1, 128, 112, 112]               0\n",
      "             ReLU-37        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-38          [-1, 128, 56, 56]               0\n",
      "        AvgPool2d-39          [-1, 128, 14, 14]               0\n",
      "           Conv2d-40          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 14, 14]             256\n",
      "           Conv2d-42          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
      "           Conv2d-44          [-1, 256, 56, 56]         294,912\n",
      "      BatchNorm2d-45          [-1, 256, 56, 56]             512\n",
      "           SCConv-46          [-1, 256, 56, 56]               0\n",
      "             ReLU-47          [-1, 256, 56, 56]               0\n",
      "        AvgPool2d-48          [-1, 256, 14, 14]               0\n",
      "           Conv2d-49          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-50          [-1, 256, 14, 14]             512\n",
      "           Conv2d-51          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-52          [-1, 256, 56, 56]             512\n",
      "           Conv2d-53          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-54          [-1, 256, 56, 56]             512\n",
      "           SCConv-55          [-1, 256, 56, 56]               0\n",
      "             ReLU-56          [-1, 256, 56, 56]               0\n",
      "        AvgPool2d-57          [-1, 256, 14, 14]               0\n",
      "           Conv2d-58          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-59          [-1, 256, 14, 14]             512\n",
      "           Conv2d-60          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 56, 56]             512\n",
      "           Conv2d-62          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-63          [-1, 256, 56, 56]             512\n",
      "           SCConv-64          [-1, 256, 56, 56]               0\n",
      "             ReLU-65          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-66          [-1, 256, 28, 28]               0\n",
      "        AvgPool2d-67            [-1, 256, 7, 7]               0\n",
      "           Conv2d-68            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 7, 7]             512\n",
      "           Conv2d-70          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-71          [-1, 256, 28, 28]             512\n",
      "           Conv2d-72          [-1, 512, 28, 28]       1,179,648\n",
      "      BatchNorm2d-73          [-1, 512, 28, 28]           1,024\n",
      "           SCConv-74          [-1, 512, 28, 28]               0\n",
      "             ReLU-75          [-1, 512, 28, 28]               0\n",
      "        AvgPool2d-76            [-1, 512, 7, 7]               0\n",
      "           Conv2d-77            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-78            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-79          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-81          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "           SCConv-83          [-1, 512, 28, 28]               0\n",
      "             ReLU-84          [-1, 512, 28, 28]               0\n",
      "        AvgPool2d-85            [-1, 512, 7, 7]               0\n",
      "           Conv2d-86            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-87            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-88          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-89          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-90          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-91          [-1, 512, 28, 28]           1,024\n",
      "           SCConv-92          [-1, 512, 28, 28]               0\n",
      "             ReLU-93          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-94          [-1, 512, 14, 14]               0\n",
      "        AvgPool2d-95            [-1, 512, 3, 3]               0\n",
      "           Conv2d-96            [-1, 512, 3, 3]       2,359,296\n",
      "      BatchNorm2d-97            [-1, 512, 3, 3]           1,024\n",
      "           Conv2d-98          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-99          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-100          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-101          [-1, 512, 14, 14]           1,024\n",
      "          SCConv-102          [-1, 512, 14, 14]               0\n",
      "            ReLU-103          [-1, 512, 14, 14]               0\n",
      "       AvgPool2d-104            [-1, 512, 3, 3]               0\n",
      "          Conv2d-105            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-106            [-1, 512, 3, 3]           1,024\n",
      "          Conv2d-107          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-108          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-109          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 14, 14]           1,024\n",
      "          SCConv-111          [-1, 512, 14, 14]               0\n",
      "            ReLU-112          [-1, 512, 14, 14]               0\n",
      "       AvgPool2d-113            [-1, 512, 3, 3]               0\n",
      "          Conv2d-114            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-115            [-1, 512, 3, 3]           1,024\n",
      "          Conv2d-116          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-118          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-119          [-1, 512, 14, 14]           1,024\n",
      "          SCConv-120          [-1, 512, 14, 14]               0\n",
      "            ReLU-121          [-1, 512, 14, 14]               0\n",
      "       MaxPool2d-122            [-1, 512, 7, 7]               0\n",
      "          Linear-123                 [-1, 4096]     102,764,544\n",
      "            ReLU-124                 [-1, 4096]               0\n",
      "         Dropout-125                 [-1, 4096]               0\n",
      "          Linear-126                 [-1, 4096]      16,781,312\n",
      "            ReLU-127                 [-1, 4096]               0\n",
      "         Dropout-128                 [-1, 4096]               0\n",
      "          Linear-129                    [-1, 5]          20,485\n",
      "================================================================\n",
      "Total params: 162,169,459\n",
      "Trainable params: 162,169,459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 576.76\n",
      "Params size (MB): 618.63\n",
      "Estimated Total Size (MB): 1195.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('VGG16 and Self Calibrated Convolution Summary:')\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b148c00-447d-492c-979b-2d6f7b3d8ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCVGG16(\n",
      "  (features): Sequential(\n",
      "    (0): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): SCConv(\n",
      "      (k2): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k3): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (k4): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3d514c-7191-432c-89ce-94d4a3985cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função para desnormalizar as imagens\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5  # desnormalizar\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# # Função para obter o nome da classe\n",
    "# def classes(index):\n",
    "#     classes = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Traffic Light']\n",
    "#     return classes[index]\n",
    "\n",
    "# dataiter = iter(test_loader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# # Mover as imagens para o dispositivo correto e obter previsões\n",
    "# images = images.to(device)\n",
    "# outputs = model(images)\n",
    "# _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# # Plotar imagens com previsões e etiquetas verdadeiras\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# for idx in np.arange(20):\n",
    "#     ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
    "#     img = images[idx].cpu().numpy()  # Mover a imagem para a CPU antes de usar np.transpose\n",
    "#     img = img / 2 + 0.5  # desnormalizar\n",
    "#     plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "#     ax.set_title(\"{} ({})\".format(classes(predicted[idx]), classes(labels[idx])),\n",
    "#                  color=(\"green\" if predicted[idx]==labels[idx].item() else \"red\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fde1853-f34d-458a-8e68-6a7302920b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_predictions(loader, model, num_images=8):\n",
    "#     images, labels = next(iter(loader))\n",
    "#     outputs = model(images)\n",
    "#     _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     for i in range(num_images):\n",
    "#         plt.subplot(2, 4, i + 1)\n",
    "#         plt.imshow(images[i].permute(1, 2, 0))\n",
    "#         plt.title(f'{\"Green\" if predicted[i] == labels[i] else \"Red\"}: {predicted[i]}({labels[i]})')\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # Visualizar as previsões\n",
    "# visualize_predictions(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e918c3d3-a546-4f5a-8e28-b0982e0492e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = range(1, len(train_loss) + 1)\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, train_loss, 'r', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs, train_accuracy, 'r', label='Training Accuracy')\n",
    "# plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
